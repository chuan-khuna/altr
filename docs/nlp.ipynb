{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6689a7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "from pythainlp.tokenize import word_tokenize\n",
    "from pymonad.tools import curry\n",
    "\n",
    "import gensim\n",
    "\n",
    "\n",
    "from altr.nlp import compose, exclude_by_regex, prepare_data_for_ngram, process_ngram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a4fd9e",
   "metadata": {},
   "source": [
    "load example texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "064fca43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[':3', '‚ò∫Ô∏è', 'ü§§', 'ü§™', 'üòÅ', 'üòÑ', 'üòä', 'üòã', 'üòç', 'üòò']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(\"https://raw.githubusercontent.com/PyThaiNLP/wisesight-sentiment/refs/heads/master/pos.txt\")\n",
    "\n",
    "texts = [text.strip() for text in response.text.split(\"\\n\")]\n",
    "texts[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0186e8ce",
   "metadata": {},
   "source": [
    "define tokeniser function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8971a675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenise(texts):\n",
    "    return [word_tokenize(text, engine=\"newmm\", keep_whitespace=False) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e2b25e",
   "metadata": {},
   "source": [
    "define some functions for text and token processing pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41253543",
   "metadata": {},
   "outputs": [],
   "source": [
    "@curry(2)\n",
    "def filter_by_length(length: int, texts: list[str]) -> list[str]:\n",
    "    return [text for text in texts if len(text) >= length]\n",
    "\n",
    "\n",
    "@curry(2)\n",
    "def filter_list_tokens_by_regex(pattern: str, list_of_tokens: list[list[str]]) -> list[list[str]]:\n",
    "    return [exclude_by_regex(pattern)(tokens) for tokens in list_of_tokens]\n",
    "\n",
    "\n",
    "@curry(2)\n",
    "def train_ngram_model(kwargs: dict, tokenised_texts: list[list[str]]) -> gensim.models.Phrases:\n",
    "    return gensim.models.Phrases(tokenised_texts, **kwargs)\n",
    "\n",
    "\n",
    "def apply_ngram_model(ngram_model: gensim.models.Phrases, tokenised_texts: list[list[str]]) -> list[list[str]]:\n",
    "    return [ngram_model[tokens] for tokens in tokenised_texts]\n",
    "\n",
    "\n",
    "@curry(2)\n",
    "def filter_only_ngram_tokens(delimiter, tokenised_texts: list[list[str]]) -> list[list[str]]:\n",
    "    return [[token for token in tokens if delimiter in token] for tokens in tokenised_texts]\n",
    "\n",
    "\n",
    "@curry(2)\n",
    "def concat_ngram_tokens(delimiter, tokenised_texts: list[list[str]]) -> list[list[str]]:\n",
    "    return [[token.replace(delimiter, \"\") for token in tokens] for tokens in tokenised_texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f6625f",
   "metadata": {},
   "source": [
    "create pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cce0c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "NGRAM_DELIMITER = \"<DELIM>\"\n",
    "\n",
    "process_bigram = process_ngram(\n",
    "    train_ngram_model({\"min_count\": 1, \"threshold\": 0.1, \"delimiter\": NGRAM_DELIMITER}),\n",
    "    apply_ngram_model,\n",
    "    filter_only_ngram_tokens(NGRAM_DELIMITER),\n",
    "    concat_ngram_tokens(NGRAM_DELIMITER),\n",
    ")\n",
    "\n",
    "process_trigram = process_ngram(\n",
    "    train_ngram_model({\"min_count\": 1, \"threshold\": 0.1, \"delimiter\": NGRAM_DELIMITER}),\n",
    "    apply_ngram_model,\n",
    "    filter_only_ngram_tokens(NGRAM_DELIMITER),\n",
    "    concat_ngram_tokens(NGRAM_DELIMITER),\n",
    ")\n",
    "\n",
    "\n",
    "generate_ngram_pipeline = compose(\n",
    "    # filter long enough texts\n",
    "    filter_by_length(20),\n",
    "    tokenise,\n",
    "    filter_list_tokens_by_regex(r\"^5\"),\n",
    "    filter_list_tokens_by_regex(r\"^\\s+$\"),\n",
    "    # --- train ngram models below ---\n",
    "    prepare_data_for_ngram,\n",
    "    process_bigram,\n",
    "    process_trigram,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bedd3e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = generate_ngram_pipeline(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9caa1346",
   "metadata": {},
   "outputs": [],
   "source": [
    "models, ngrams, ngrams_filtered = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e368463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['‡∏Å‡∏¥‡∏ô‡∏ô‡πâ‡∏≥‡∏ã‡∏∏‡∏õ', '‡∏ô‡∏∞‡∏≠‡∏£‡πà‡∏≠‡∏¢'],\n",
       " ['‡∏ô‡∏∞‡∏°‡∏∂‡∏á'],\n",
       " [],\n",
       " ['‡∏Ñ‡∏¥‡∏î‡∏ñ‡∏∂‡∏á‡πÅ‡∏°‡πà'],\n",
       " ['‡πÄ‡∏Ñ‡∏£', '‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà'],\n",
       " ['‡πÉ‡∏Ñ‡∏£‡∏ß‡πà‡∏≤', '‡∏à‡∏∞‡πÄ‡∏•‡∏µ‡πâ‡∏¢‡∏á'],\n",
       " ['‡∏ä‡πà‡∏ß‡∏á‡∏ô‡∏µ‡πâ‡∏à‡∏∞', '‡∏Å‡∏£‡∏≠‡∏ö‡πÜ'],\n",
       " ['‡∏ä‡πà‡∏ß‡∏¢‡πÜ', '‡∏î‡πâ‡∏ß‡∏¢‡∏ô‡∏∞'],\n",
       " ['‡∏ä‡∏≠‡∏ö‡∏Å‡∏¥‡∏ô', '‡∏ä‡πâ‡∏≤‡∏á‡∏Ñ‡∏£‡∏±‡∏ö', '‡∏û‡∏µ‡πà‡∏ô‡πâ‡∏≥'],\n",
       " ['‡πÄ‡∏°‡∏ô‡∏π‡∏Ç‡∏≠‡∏á']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bigram from the first 10 texts\n",
    "ngrams_filtered[2][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47831650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e90171",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
