{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20845311",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythainlp.tokenize import word_tokenize\n",
    "import pythainlp\n",
    "import re\n",
    "import requests\n",
    "\n",
    "import gensim\n",
    "from pymonad.tools import curry\n",
    "\n",
    "\n",
    "from typing import TypeAlias\n",
    "\n",
    "Text: TypeAlias = str\n",
    "Word: TypeAlias = str\n",
    "Token: TypeAlias = str\n",
    "\n",
    "NGRAM_DELIMITER = \"<DELIM>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e830bdf6",
   "metadata": {},
   "source": [
    "Load dataset\n",
    "\n",
    "- https://github.com/PyThaiNLP/wisesight-sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2dcdc04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[':3', 'â˜ºï¸', 'ðŸ¤¤', 'ðŸ¤ª', 'ðŸ˜', 'ðŸ˜„', 'ðŸ˜Š', 'ðŸ˜‹', 'ðŸ˜', 'ðŸ˜˜']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(\"https://raw.githubusercontent.com/PyThaiNLP/wisesight-sentiment/refs/heads/master/pos.txt\")\n",
    "\n",
    "texts = [text.strip() for text in response.text.split(\"\\n\")]\n",
    "texts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29cabf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose(*functions):\n",
    "    def take_input(x):\n",
    "        result = x\n",
    "        for function in functions:\n",
    "            result = function(result)\n",
    "        return result\n",
    "\n",
    "    return take_input\n",
    "\n",
    "\n",
    "pipe = compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13af2f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "@curry(2)\n",
    "def filter_by_length(length: int, texts: list[Text]) -> list[Text]:\n",
    "    return [text for text in texts if len(text) >= length]\n",
    "\n",
    "\n",
    "def tokenize(texts: list[Text]) -> list[list[Token]]:\n",
    "    return [word_tokenize(text, keep_whitespace=False) for text in texts]\n",
    "\n",
    "\n",
    "# models, ngrams, ngrams_filtered\n",
    "def prepare_data_for_ngram(\n",
    "    tokenised_texts: list[list[Token]],\n",
    ") -> tuple[dict[int, gensim.models.Phrases | None], dict[int, list[list[Token]]], dict[int, list[list[Token]]]]:\n",
    "    return ({1: None}, {1: tokenised_texts}, {1: tokenised_texts})\n",
    "\n",
    "\n",
    "def _train_ngram_model(model_kwargs: dict, tokenised_texts: list[Text]) -> gensim.models.Phrases:\n",
    "    model = gensim.models.Phrases(tokenised_texts, delimiter=NGRAM_DELIMITER, **model_kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def _get_ngram_tokens(model: gensim.models.Phrases, tokenised_texts: list[list[Token]]) -> list[list[Token]]:\n",
    "    return [model[tokens] for tokens in tokenised_texts]\n",
    "\n",
    "\n",
    "def _fit_transform_ngram_models(\n",
    "    model_kwargs,\n",
    "    tokenised_texts: list[list[Token]],\n",
    "):\n",
    "    model = _train_ngram_model(model_kwargs, tokenised_texts)\n",
    "    result = _get_ngram_tokens(model, tokenised_texts)\n",
    "    return model, result\n",
    "\n",
    "\n",
    "def _filter_only_ngram_tokens(tokenised_texts: list[list[Token]]) -> list[list[Token]]:\n",
    "    return [[token for token in tokens if NGRAM_DELIMITER in token] for tokens in tokenised_texts]\n",
    "\n",
    "\n",
    "def _concat_ngram_tokens(tokenised_texts: list[list[Token]]) -> list[list[Token]]:\n",
    "    return [[token.replace(NGRAM_DELIMITER, \"\") for token in tokens] for tokens in tokenised_texts]\n",
    "\n",
    "\n",
    "def process_ngram(model_kwargs):\n",
    "    filter_ngram_pipeline = compose(_filter_only_ngram_tokens, _concat_ngram_tokens)\n",
    "\n",
    "    def process(input_tuple):\n",
    "        # extract data from input tuple\n",
    "        models = input_tuple[0]\n",
    "        ngram_tokens = input_tuple[1]\n",
    "        ngram_tokens_filtered = input_tuple[2]\n",
    "\n",
    "        # find the previous number of ngram\n",
    "        max_available_ngram = max(models.keys())\n",
    "        next_ngram = max_available_ngram + 1\n",
    "\n",
    "        model_input = ngram_tokens[max_available_ngram]\n",
    "\n",
    "        model, ngram_result = _fit_transform_ngram_models(model_kwargs, model_input)\n",
    "        ngram_result_filtered = filter_ngram_pipeline(ngram_result)\n",
    "        ngram_result = _concat_ngram_tokens(ngram_result)\n",
    "\n",
    "        # assign data to the memory\n",
    "        models[next_ngram] = model\n",
    "        ngram_tokens[next_ngram] = ngram_result\n",
    "        ngram_tokens_filtered[next_ngram] = ngram_result_filtered\n",
    "\n",
    "        return models, ngram_tokens, ngram_tokens_filtered\n",
    "\n",
    "    return process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1c4e451",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_ngram_pipeline = compose(\n",
    "    # do something with list of texts here\n",
    "    filter_by_length(20),\n",
    "    tokenize,\n",
    "    # do something with list of tokens here\n",
    "    # ...\n",
    "    # --- train ngram models below ---\n",
    "    prepare_data_for_ngram,\n",
    "    process_ngram({\"min_count\": 1, \"threshold\": 0.1}),\n",
    "    process_ngram({\"min_count\": 1, \"threshold\": 0.1}),\n",
    "    process_ngram({\"min_count\": 1, \"threshold\": 0.1}),\n",
    ")\n",
    "\n",
    "tokenised_texts = generate_ngram_pipeline(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9530a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
